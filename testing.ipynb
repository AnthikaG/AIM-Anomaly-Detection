{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pytorch_i3d import InceptionI3d\n",
    "import moviepy.editor as mp\n",
    "\n",
    "!pip3 install av\n",
    "import av\n",
    "print(av.__version__)\n",
    "\n",
    "# !pip3 install opencv-python\n",
    "!pip3 install opencv-contrib-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_rgb(video_path, video_name, new_rgb_root = \"./test_rgb\"):\n",
    "    os.makedirs(os.path.join(new_rgb_root, video_name), exist_ok=True)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 1\n",
    "    while success:\n",
    "        cv2.imwrite(os.path.join(new_rgb_root, video_name, video_name + \"-%s.jpg\" % str(count).zfill(6)), image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir = \"test_videos\"\n",
    "for category in os.listdir(dir):\n",
    "  for video in os.listdir(os.path.join(dir, category)):\n",
    "    video_to_rgb(os.path.join(\"test_videos\", category, video), video.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.device(0))\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "rgb_i3d = InceptionI3d(400, in_channels=3)\n",
    "rgb_i3d.replace_logits(8)\n",
    "rgb_i3d.load_state_dict(torch.load(\"./newmodels_info/Training3/bnModel005000.pt\", map_location=torch.device(device)))\n",
    "rgb_i3d.eval()\n",
    "flow_i3d = InceptionI3d(400, in_channels=2)\n",
    "flow_i3d.replace_logits(8)\n",
    "flow_i3d.load_state_dict(torch.load(\"./newmodels_info/Training1/flow_anamoly005000.pt\", map_location=torch.device(device)))\n",
    "flow_i3d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charades_dataset import load_rgb_frames, load_flow_frames, video_to_tensor\n",
    "import videotransforms\n",
    "\n",
    "cropTransform = transforms.Compose([videotransforms.CenterCrop(224)])\n",
    "\n",
    "def predict(rgb_root, flow_root, video):\n",
    "  rgb_imgs = load_rgb_frames(rgb_root, video, 1, int(len(os.listdir(os.path.join(rgb_root, video)))))\n",
    "  rgb_imgs = cropTransform(rgb_imgs)\n",
    "  rgb_input = video_to_tensor(rgb_imgs)\n",
    "  rgb_input = rgb_input[None] # batch size of 1\n",
    "\n",
    "  flow_imgs = load_flow_frames(flow_root, video, 1, int(len(os.listdir(os.path.join(flow_root, video)))/2))\n",
    "  flow_imgs = cropTransform(flow_imgs)\n",
    "  flow_input = video_to_tensor(flow_imgs)\n",
    "  flow_input = flow_input[None] # batch size of 1\n",
    "  with torch.no_grad():\n",
    "      rgb_prediction = rgb_i3d(rgb_input)\n",
    "      flow_prediction = flow_i3d(flow_input)\n",
    "  prediction = (rgb_prediction + flow_prediction)/2.0\n",
    "  averaged_prediction = torch.mean(prediction, dim=2)[0]\n",
    "  normalized_prediction = torch.softmax(averaged_prediction, dim=0)\n",
    "  print(\"PREDICTION|\"+str(video)+\"|\")\n",
    "  for p in normalized_prediction:\n",
    "    print(p.item(), end=\" \")\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for category in os.listdir(\"test_videos\"):\n",
    "  for video in os.listdir(os.path.join(\"test_videos\", category)):\n",
    "    predict(\"test_rgb\", \"test_flow\", video.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
