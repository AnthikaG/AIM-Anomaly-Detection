{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pytorch_i3d import InceptionI3d\n",
    "import moviepy.editor as mp\n",
    "\n",
    "!pip3 install av\n",
    "import av\n",
    "print(av.__version__)\n",
    "\n",
    "# !pip3 install opencv-python\n",
    "!pip3 install opencv-contrib-python\n",
    "import cv2\n",
    "from denseflow import dense_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize videos while maintaining aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(old_video_path, new_video_name, new_video_root = \"./demo_videos\"):\n",
    "    os.makedirs(os.path.join(new_video_root), exist_ok=True)\n",
    "    clip = mp.VideoFileClip(old_video_path, audio=False)\n",
    "    if(clip.w > clip.h):\n",
    "        clip_resized = clip.resize(height=224) \n",
    "    else:\n",
    "        clip_resized = clip.resize(width=224)\n",
    "    clip_resized.write_videofile(os.path.join(new_video_root, new_video_name + \".mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./demo_videos\\campfire.mp4.\n",
      "Moviepy - Writing video ./demo_videos\\campfire.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./demo_videos\\campfire.mp4\n"
     ]
    }
   ],
   "source": [
    "resize_video(\"temp_videos/campfire.mp4\", \"campfire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_rgb(video_path, video_name, new_rgb_root = \"./demo_rgb\"):\n",
    "    os.makedirs(os.path.join(new_rgb_root, video_name), exist_ok=True)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 1\n",
    "    while success:\n",
    "        cv2.imwrite(os.path.join(new_rgb_root, video_name, video_name + \"-%s.jpg\" % str(count).zfill(6)), image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_rgb(\"./demo_videos/campfire.mp4\", \"campfire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_flow(video_path, video_name, new_flow_root = \"./demo_flow\"):\n",
    "    os.makedirs(os.path.join(new_flow_root, video_name), exist_ok=True)\n",
    "    step = 1\n",
    "    bound = 15\n",
    "    dense_flow_args = [video_path, video_name, new_flow_root, step, bound]\n",
    "    dense_flow(dense_flow_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_flow(\"./demo_videos/campfire.mp4\", \"campfire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.device(0))\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "rgb_i3d = InceptionI3d(400, in_channels=3)\n",
    "rgb_i3d.replace_logits(8)\n",
    "rgb_i3d.load_state_dict(torch.load(\"./newmodels_info/Training3/bnModel005000.pt\", map_location=torch.device(device)))\n",
    "rgb_i3d.eval()\n",
    "flow_i3d = InceptionI3d(400, in_channels=2)\n",
    "flow_i3d.replace_logits(8)\n",
    "flow_i3d.load_state_dict(torch.load(\"./newmodels_info/Training1/flow_anamoly005000.pt\", map_location=torch.device(device)))\n",
    "flow_i3d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charades_dataset import load_rgb_frames, load_flow_frames, video_to_tensor\n",
    "import videotransforms\n",
    "\n",
    "cropTransform = transforms.Compose([videotransforms.CenterCrop(224)])\n",
    "\n",
    "rgb_root = \"./demo_rgb\"\n",
    "flow_root = \"./demo_flow\"\n",
    "video = \"campfire\"\n",
    "\n",
    "rgb_imgs = load_rgb_frames(rgb_root, video, 1, int(len(os.listdir(os.path.join(rgb_root, video)))))\n",
    "rgb_imgs = cropTransform(rgb_imgs)\n",
    "rgb_input = video_to_tensor(rgb_imgs)\n",
    "rgb_input = rgb_input[None] # batch size of 1\n",
    "\n",
    "flow_imgs = load_flow_frames(flow_root, video, 1, int(len(os.listdir(os.path.join(flow_root, video)))/2))\n",
    "flow_imgs = cropTransform(flow_imgs)\n",
    "flow_input = video_to_tensor(flow_imgs)\n",
    "flow_input = flow_input[None] # batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: Arson\n",
    "# 1: Assault\n",
    "# 2: Fighting\n",
    "# 3: RoadAccidents\n",
    "# 4: Shooting\n",
    "# 5: Stealing\n",
    "# 6: Vandalism\n",
    "# 7: Normal\n",
    "classes = [\"Arson\", \"Assault\", \"Fighting\", \"RoadAccidents\", \"Shooting\", \"Stealing\", \"Vandalism\", \"Normal\"]\n",
    "# shape=(_BATCH_SIZE, _CHANNELS, _SAMPLE_VIDEO_FRAMES, _IMAGE_SIZE, _IMAGE_SIZE))\n",
    "with torch.no_grad():\n",
    "    rgb_prediction = rgb_i3d(rgb_input)\n",
    "    flow_prediction = flow_i3d(flow_input)\n",
    "prediction = (rgb_prediction + flow_prediction)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_prediction = torch.mean(prediction, dim=2)[0]\n",
    "# print(averaged_prediction)\n",
    "normalized_prediction = torch.softmax(averaged_prediction, dim=0)\n",
    "# print([format(p, '.5f') for p in normalized_prediction])\n",
    "final_class_index = torch.argmax(normalized_prediction)\n",
    "# print(classes[final_class_index])\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "t = PrettyTable(['Class', 'Probability'])\n",
    "prediction_rows = [(i, normalized_prediction[i].item()) for i in range(8)]\n",
    "from functools import cmp_to_key\n",
    "prediction_rows = sorted(prediction_rows, reverse=True, key=cmp_to_key(lambda item1, item2: item1[1] - item2[1]))\n",
    "for p in prediction_rows:\n",
    "  t.add_row([classes[p[0]], format(p[1], '.5f')])\n",
    "print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
